---
title: "p8105_hw6_zlb2008"
author: "Zakari L. Billo"
date: "2025-12-03"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(broom)
library(purrr)
library(p8105.datasets)
library(modelr)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.height = 7,
  fig.align = "center",
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 

```{r}
homicide_df <- read.csv('data/homicide-data.csv', na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |>
  mutate(
    victim_age = as.numeric(victim_age),
    case_outcome = ifelse(disposition == "Closed by arrest", 1, 0)
  ) |>
  filter(!is.na(victim_age)) |>
  select(city_state, case_outcome, victim_age, victim_sex, victim_race)
```

glm for Baltimore, MD

```{r}
bmore_results <-
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(
    case_outcome ~ victim_age + victim_sex + victim_race,
    family = binomial(),
    data = _
  ) |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(
    OR = exp(estimate),
    CL_low = exp(conf.low),
    CL_high = exp(conf.high)
  ) |>
  filter(term == "victim_sexMale") |>
  select(term, log_OR = estimate, OR, CL_low, CL_high, p.value)

bmore_results |> knitr::kable(digits = 3)
```
The odds ratio for solved homocides among male victims compared to that among female victims in Baltimore, MD is 0.426 (95% CI: 0.324, 0.558), adjusting for victim age and race.

```{r}
city_results <-
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    fit = map(
      data,
      ~ glm(case_outcome ~ victim_age + victim_sex + victim_race,
            family = binomial(), data = .x)
    ),
    tidy_fit = map(fit, ~ broom::tidy(.x, conf.int = TRUE))
  ) |>
  unnest(tidy_fit) |>
  filter(term == "victim_sexMale") |>
  mutate(
    OR = exp(estimate),
    CL_low = exp(conf.low),
    CL_high = exp(conf.high)
  ) |>
  select(city_state, OR, CL_low, CL_high, p.value)

city_results |> 
  knitr::kable(digits = 3)
```
plot the ORs 

```{r}
city_results |>
  mutate(city_state = fct_reorder(city_state, OR)) |>
  ggplot(aes(y = city_state, x = OR)) +
  geom_point(size = 2) +
  geom_errorbarh(aes(xmin = CL_low, xmax = CL_high), height = 0.15) +
  geom_vline(xintercept = 1, color = "red", linetype = "dotted") +
  labs(
    title = "Adjusted Odds Ratio for Solved Homicides: Male vs Female Victims",
    x = "Odds Ratio (adjusted for age & race)",
    y = "City"
  ) +
  theme_minimal()
```

The plot of ORs by city shows that most cities have a lower odds of solving homicide cases for male victims compared to female victims. 

Albuquerque, NM; Stockton, CA; and Fresno, CA are the exception given that they have the highest estimated odds ratios, meaning that homicides with male victim are more likely to be solved than homicides with female victims. However, most of these cities' estimated ORs have confidence intervals that include the null, implying there is no statistically significant evidence of a difference in the odds of solving homicides between male and female victims.

New York, NY; Baton Rouge, LA; and Omaha, NE have the lowest odds of solving homicide cases for male victims compared to female victims. The OR confidence intervals for these cities is below 1, providing statistically significant evidence for lower solve rates among male-victim cases.

## Problem 2 

```{r}
data("weather_df")
set.seed(1)

bootstrap_results <-
  weather_df |>
  bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results_glance = map(models, broom::glance),
    results_tidy = map(models, broom::tidy)
  ) |>
  select(-strap, -models) |>
  unnest(results_glance) |>
  select(.id, r.squared, results_tidy) |>
  unnest(results_tidy) |>
  select(.id, r.squared, term, estimate) |>
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |>
  mutate(
    beta_ratio = tmin / prcp
  )
```

make plots

```{r}
p1 <- bootstrap_results |>
  ggplot(aes(x = r.squared)) +
  geom_density(fill = "violet", alpha = 0.5) +
  labs(title = "Bootstrap Distribution of R^2", x = "RÂ²")

p2 <- bootstrap_results |>
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(title = "Distribution of Beta_1/Beta_2", x = "Coefficient Ratio")

p1 + p2
```

make table 

```{r}
ci_results <- 
  bootstrap_results |>
  summarize(
    R_sq_low = quantile(r.squared, 0.025),
    R_sq_high = quantile(r.squared, 0.975),
    beta_ratio_low = quantile(beta_ratio, 0.025),
    beta_ratio_high = quantile(beta_ratio, 0.975)
  )

knitr::kable(ci_results, digits = 3)
```
The 95% CI for $\frac{\beta_1}{\beta_2}$ is approximately (-278, -126). The CI does not cross 0, so the ratio is consistently negative and not due to chance.


## Problem 3

turn relevant vars into factors 

```{r}
birthweight_df = read_csv("data/birthweight.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("Male", "Female")),
    
    frace = factor(frace, 
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    
    malform = factor(malform, 
                     levels = c(0, 1),
                     labels = c("Absent", "Present"))
  )

summary(is.na(birthweight_df))
```

I propose the following predictors drive infant birthweight:

Malformations (malform)

Gestational age (gaweeks)

Maternal age at delivery (momage)

Pre-pregnancy BMI (ppbmi)

Weight gain during pregnancy (wtgain)

Smoking during pregnancy (smoken)

Maternal race (mrace)

Fraternal race (frace)

Family income (fincome)

I removed variables from my model like pnumlbw (previous low birthweight babies) and parity because they provided no additional explanatory power. Infant physical measurements (blength, bhead) were ommitted, since they aren't predictive of the infants birthweight at delivery.

```{r}
main_bw_model =
  lm(
    bwt ~ malform + gaweeks + momage + ppbmi + wtgain + smoken + mrace + frace + fincome,
    data = birthweight_df
  )

summary(main_bw_model)
```

now add residuals 

```{r}
birthweight_df |> 
  add_predictions(main_bw_model) |> 
  add_residuals(main_bw_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Main Model)",
    x = "Fitted Values (Predicted Infant Birthweight)",
    y = "Residuals"
  ) +
  theme_minimal()
```

make a simple model and one with interaction

```{r}
simple_bw_model =
  lm(bwt ~ blength + gaweeks, data = birthweight_df)

interation_bw_model =
  lm(bwt ~ bhead * blength * gaweeks, data = birthweight_df)
```

compare to main model

```{r}
set.seed(1)

cv_df =
  crossv_mc(birthweight_df, n = 5000) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble)
  )

cv_df =
  cv_df |>
  mutate(
    main_model = map(train, \(df) lm(bwt ~ malform + gaweeks + momage + ppbmi + wtgain + smoken + mrace + frace + fincome,
    data = df)),
    simple_model = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_model  = map(train, \(df) lm(bwt ~ bhead * blength * gaweeks, data = df))
  )

cv_df =
  cv_df |>
  mutate(
    rmse_main = map2_dbl(main_model, test, rmse),
    rmse_simple = map2_dbl(simple_model, test, rmse),
    rmse_interaction  = map2_dbl(interaction_model, test, rmse)
  )

cv_long =
  cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |>
  mutate(
    model = fct_inorder(recode(model,
                               main   = "Main model",
                               simple = "Length + GA",
                               inter  = "3-way interaction"))
  )

cv_long |>
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin(alpha = 0.5, color = "blue") +
  scale_fill_viridis_d() +
  labs(
    title = "Cross-Validation Model Comparison",
    x = "Model",
    y = "Root Mean Squared Error (RMSE)"
  ) +
  theme_minimal()
```

The cross-validated RMSE plot shows a large difference in predictive performance across the models. My main model has by far the highest RMSE values, meaning it predicting birthweight with the highest error. The Length + Gestational Age model performs better, with lower RMSE values. Finally, the full interaction model (incorporates head circumference, length, sex, and all their lower-order interaction) has the the lowest RMSE overall and best predictive performance.
